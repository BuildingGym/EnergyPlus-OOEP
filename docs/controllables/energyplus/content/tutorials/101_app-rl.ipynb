{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“š Case Study 101: Reinforcement Learning Based Control\n",
    "\n",
    "Before you start:\n",
    "- Make sure you have the following packages installed:\n",
    "    - ~~`controllables-energyplus`~~ (`pip`): see 000_intro.ipynb (TODO hyperlink)\n",
    "\n",
    "What you will learn in this chapter:\n",
    "- TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from controllables.energyplus.examples import system_1zone_evapcooler\n",
    "\n",
    "system = system_1zone_evapcooler.make_system(repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ef9a77278b4b2a989d17ec3716546f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<controllables.energyplus.systems.System at 0x7f1ec7124710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.add('logging:progress').start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO cite\n",
    "Configure the controller (powered by RLlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/user/lab/EnergyPlus-OOEP/.venv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:500: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/AD/user/lab/EnergyPlus-OOEP/.venv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/AD/user/lab/EnergyPlus-OOEP/.venv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/AD/user/lab/EnergyPlus-OOEP/.venv/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-09-23 12:19:23,206\tWARNING env.py:89 -- Env checking isn't implemented for RemoteBaseEnvs, ExternalMultiAgentEnv, ExternalEnvs or environments that are Ray actors.\n",
      "2024-09-23 12:19:23,920\tWARNING util.py:62 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "import numpy as _numpy_\n",
    "import gymnasium as _gymnasium_\n",
    "\n",
    "from controllables.energyplus import (\n",
    "    Actuator,\n",
    "    OutputVariable,\n",
    ")\n",
    "from controllables.core.tools.gymnasium import (\n",
    "    BoxSpace,\n",
    "    DictSpace,\n",
    ")\n",
    "from controllables.core.tools.ray import ExternalEnv\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPO, PPOConfig\n",
    "from ray.rllib.algorithms.callbacks import DefaultCallbacks\n",
    "\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(\n",
    "        ExternalEnv, \n",
    "        env_config=ExternalEnv.Config(\n",
    "            action_space=DictSpace({\n",
    "                'thermostat': BoxSpace(\n",
    "                    low=15., high=20.,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(\n",
    "                    Actuator.Ref(\n",
    "                        type='Zone Temperature Control',\n",
    "                        control_type='Heating Setpoint',\n",
    "                        key='MAIN ZONE',\n",
    "                    )            \n",
    "                )\n",
    "            }),    \n",
    "            observation_space=DictSpace({\n",
    "                'temperature': BoxSpace(\n",
    "                    low=-_numpy_.inf, high=+_numpy_.inf,\n",
    "                    dtype=_numpy_.float32,\n",
    "                    shape=(),\n",
    "                ).bind(\n",
    "                    OutputVariable.Ref(\n",
    "                        type='Zone Air Temperature',\n",
    "                        key='MAIN ZONE',\n",
    "                    )\n",
    "                ),\n",
    "            }),\n",
    "            system=lambda: system,\n",
    "            reward_function=lambda agent: 1,\n",
    "            episode_events={\n",
    "                'step': 'begin_zone_timestep_after_init_heat_balance',\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    .rollouts(\n",
    "        create_env_on_local_worker=True,\n",
    "        #num_rollout_workers=10,\n",
    "        num_rollout_workers=0,\n",
    "        enable_connectors=False,\n",
    "    )\n",
    "    .framework('torch')\n",
    "    .evaluation(\n",
    "        #evaluation_interval=1,\n",
    "        #evaluation_num_workers=0\n",
    "    )\n",
    "    .resources(num_gpus=1.)\n",
    ")\n",
    "\n",
    "algo = PPO(\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/tools/ray/env.py:234: RuntimeWarning: Observation required to end the episode; got TemporaryUnavailableError()\n",
      "  _warnings_.warn(\n",
      "2024-09-23 12:19:31,200\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.938514394657586, 'policy_loss': -0.06153002535143206, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.00022207255682079322, 'entropy': 1.4278103168292713, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 465.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 351.940333235817, 'num_env_steps_trained_throughput_per_sec': 351.940333235817, 'timesteps_total': 4000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 4000, 'timers': {'training_iteration_time_ms': 11365.545, 'sample_time_ms': 7237.998, 'load_time_ms': 0.561, 'load_throughput': 7133170.068, 'learn_time_ms': 4126.107, 'learn_throughput': 969.437, 'synch_weights_time_ms': 0.004}, 'counters': {'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'done': False, 'episodes_total': 0, 'training_iteration': 1, 'trial_id': 'default', 'date': '2024-09-23_12-19-35', 'timestamp': 1727093975, 'time_this_iter_s': 11.365640640258789, 'time_total_s': 11.365640640258789, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 11.365640640258789, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 4.564705882352942, 'ram_util_percent': 16.594117647058823}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.10000000000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.938191715363534, 'policy_loss': -0.062094443820176586, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.002861794302745732, 'entropy': 1.4193973375904945, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 1395.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000, 'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 422.0520076997274, 'num_env_steps_trained_throughput_per_sec': 422.0520076997274, 'timesteps_total': 8000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 8000, 'timers': {'training_iteration_time_ms': 10421.519, 'sample_time_ms': 6378.786, 'load_time_ms': 0.545, 'load_throughput': 7334302.077, 'learn_time_ms': 4041.638, 'learn_throughput': 989.698, 'synch_weights_time_ms': 0.004}, 'counters': {'num_env_steps_sampled': 8000, 'num_env_steps_trained': 8000, 'num_agent_steps_sampled': 8000, 'num_agent_steps_trained': 8000}, 'done': False, 'episodes_total': 0, 'training_iteration': 2, 'trial_id': 'default', 'date': '2024-09-23_12-19-44', 'timestamp': 1727093984, 'time_this_iter_s': 9.4775869846344, 'time_total_s': 20.84322762489319, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 20.84322762489319, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 4.7846153846153845, 'ram_util_percent': 16.74615384615384}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.05000000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937181777338829, 'policy_loss': -0.06308036336014347, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.00524325519531054, 'entropy': 1.3633428232644194, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 2325.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000, 'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 423.69209635892383, 'num_env_steps_trained_throughput_per_sec': 423.69209635892383, 'timesteps_total': 12000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 12000, 'timers': {'training_iteration_time_ms': 10094.615, 'sample_time_ms': 6093.076, 'load_time_ms': 0.53, 'load_throughput': 7551635.109, 'learn_time_ms': 4000.57, 'learn_throughput': 999.858, 'synch_weights_time_ms': 0.003}, 'counters': {'num_env_steps_sampled': 12000, 'num_env_steps_trained': 12000, 'num_agent_steps_sampled': 12000, 'num_agent_steps_trained': 12000}, 'done': False, 'episodes_total': 0, 'training_iteration': 3, 'trial_id': 'default', 'date': '2024-09-23_12-19-54', 'timestamp': 1727093994, 'time_this_iter_s': 9.440885543823242, 'time_total_s': 30.28411316871643, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 30.28411316871643, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 4.507142857142857, 'ram_util_percent': 16.72142857142857}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.05000000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.938037685681415, 'policy_loss': -0.06218579755995863, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.004469562564714892, 'entropy': 1.3657055566387792, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 3255.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000, 'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 434.944263842914, 'num_env_steps_trained_throughput_per_sec': 434.944263842914, 'timesteps_total': 16000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 16000, 'timers': {'training_iteration_time_ms': 9870.103, 'sample_time_ms': 5907.323, 'load_time_ms': 0.52, 'load_throughput': 7698619.25, 'learn_time_ms': 3961.847, 'learn_throughput': 1009.63, 'synch_weights_time_ms': 0.003}, 'counters': {'num_env_steps_sampled': 16000, 'num_env_steps_trained': 16000, 'num_agent_steps_sampled': 16000, 'num_agent_steps_trained': 16000}, 'done': False, 'episodes_total': 0, 'training_iteration': 4, 'trial_id': 'default', 'date': '2024-09-23_12-20-03', 'timestamp': 1727094003, 'time_this_iter_s': 9.196653604507446, 'time_total_s': 39.48076677322388, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 39.48076677322388, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 4.7615384615384615, 'ram_util_percent': 16.776923076923076}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.93663087250084, 'policy_loss': -0.06359594663785349, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.00907340721528907, 'entropy': 1.3605241637076102, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 4185.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000, 'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 444.7988225244793, 'num_env_steps_trained_throughput_per_sec': 444.7988225244793, 'timesteps_total': 20000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 20000, 'timers': {'training_iteration_time_ms': 9694.646, 'sample_time_ms': 5773.801, 'load_time_ms': 0.509, 'load_throughput': 7864811.551, 'learn_time_ms': 3919.964, 'learn_throughput': 1020.417, 'synch_weights_time_ms': 0.003}, 'counters': {'num_env_steps_sampled': 20000, 'num_env_steps_trained': 20000, 'num_agent_steps_sampled': 20000, 'num_agent_steps_trained': 20000}, 'done': False, 'episodes_total': 0, 'training_iteration': 5, 'trial_id': 'default', 'date': '2024-09-23_12-20-12', 'timestamp': 1727094012, 'time_this_iter_s': 8.992897272109985, 'time_total_s': 48.47366404533386, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 48.47366404533386, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 4.861538461538462, 'ram_util_percent': 16.699999999999996}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.025000000000000005, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.938336891256354, 'policy_loss': -0.06170191335822305, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.0015520054676212616, 'entropy': 1.3046371048496614, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 5115.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000, 'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 447.2177970612702, 'num_env_steps_trained_throughput_per_sec': 447.2177970612702, 'timesteps_total': 24000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 24000, 'timers': {'training_iteration_time_ms': 9569.568, 'sample_time_ms': 5676.611, 'load_time_ms': 0.502, 'load_throughput': 7963238.351, 'learn_time_ms': 3892.108, 'learn_throughput': 1027.721, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 24000, 'num_env_steps_trained': 24000, 'num_agent_steps_sampled': 24000, 'num_agent_steps_trained': 24000}, 'done': False, 'episodes_total': 0, 'training_iteration': 6, 'trial_id': 'default', 'date': '2024-09-23_12-20-21', 'timestamp': 1727094021, 'time_this_iter_s': 8.944254159927368, 'time_total_s': 57.41791820526123, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 57.41791820526123, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 4.846153846153846, 'ram_util_percent': 16.699999999999996}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.012500000000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.938156109471475, 'policy_loss': -0.061938207135886277, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.007544327536782485, 'entropy': 1.2177881989427792, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 6045.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000, 'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 438.1946737244258, 'num_env_steps_trained_throughput_per_sec': 438.1946737244258, 'timesteps_total': 28000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 28000, 'timers': {'training_iteration_time_ms': 9506.537, 'sample_time_ms': 5617.172, 'load_time_ms': 0.5, 'load_throughput': 8005488.207, 'learn_time_ms': 3888.534, 'learn_throughput': 1028.665, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 28000, 'num_env_steps_trained': 28000, 'num_agent_steps_sampled': 28000, 'num_agent_steps_trained': 28000}, 'done': False, 'episodes_total': 0, 'training_iteration': 7, 'trial_id': 'default', 'date': '2024-09-23_12-20-30', 'timestamp': 1727094030, 'time_this_iter_s': 9.128429889678955, 'time_total_s': 66.54634809494019, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 66.54634809494019, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 4.8, 'ram_util_percent': 16.699999999999996}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.012500000000000002, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.938018114848804, 'policy_loss': -0.062022902275766095, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.0032807277031092633, 'entropy': 1.1384422756010486, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 6975.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000, 'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 428.3338327135504, 'num_env_steps_trained_throughput_per_sec': 428.3338327135504, 'timesteps_total': 32000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 32000, 'timers': {'training_iteration_time_ms': 9485.532, 'sample_time_ms': 5588.879, 'load_time_ms': 0.502, 'load_throughput': 7966862.231, 'learn_time_ms': 3895.835, 'learn_throughput': 1026.737, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 32000, 'num_env_steps_trained': 32000, 'num_agent_steps_sampled': 32000, 'num_agent_steps_trained': 32000}, 'done': False, 'episodes_total': 0, 'training_iteration': 8, 'trial_id': 'default', 'date': '2024-09-23_12-20-39', 'timestamp': 1727094039, 'time_this_iter_s': 9.338589906692505, 'time_total_s': 75.88493800163269, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 75.88493800163269, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 4.792307692307693, 'ram_util_percent': 16.715384615384615}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.006250000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937123235066732, 'policy_loss': -0.0629286707248739, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.00830358416242625, 'entropy': 1.1178020372185655, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 7905.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000, 'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 427.2270262114679, 'num_env_steps_trained_throughput_per_sec': 427.2270262114679, 'timesteps_total': 36000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 36000, 'timers': {'training_iteration_time_ms': 9471.884, 'sample_time_ms': 5573.461, 'load_time_ms': 0.502, 'load_throughput': 7975646.736, 'learn_time_ms': 3897.614, 'learn_throughput': 1026.269, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 36000, 'num_env_steps_trained': 36000, 'num_agent_steps_sampled': 36000, 'num_agent_steps_trained': 36000}, 'done': False, 'episodes_total': 0, 'training_iteration': 9, 'trial_id': 'default', 'date': '2024-09-23_12-20-49', 'timestamp': 1727094049, 'time_this_iter_s': 9.362760782241821, 'time_total_s': 85.24769878387451, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 85.24769878387451, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 4.8307692307692305, 'ram_util_percent': 16.723076923076917}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.006250000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.935684996779248, 'policy_loss': -0.0643993187575571, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.013489169476870497, 'entropy': 1.1136852995041877, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 8835.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000, 'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 427.45187642257065, 'num_env_steps_trained_throughput_per_sec': 427.45187642257065, 'timesteps_total': 40000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 40000, 'timers': {'training_iteration_time_ms': 9460.472, 'sample_time_ms': 5557.188, 'load_time_ms': 0.503, 'load_throughput': 7958831.12, 'learn_time_ms': 3902.484, 'learn_throughput': 1024.988, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 40000, 'num_env_steps_trained': 40000, 'num_agent_steps_sampled': 40000, 'num_agent_steps_trained': 40000}, 'done': False, 'episodes_total': 0, 'training_iteration': 10, 'trial_id': 'default', 'date': '2024-09-23_12-20-58', 'timestamp': 1727094058, 'time_this_iter_s': 9.35784101486206, 'time_total_s': 94.60553979873657, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 94.60553979873657, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 4.785714285714286, 'ram_util_percent': 16.764285714285716}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.006250000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937209135486233, 'policy_loss': -0.06284595924599837, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.00881693673799547, 'entropy': 1.0903490271619571, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 9765.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 44000, 'num_env_steps_trained': 44000, 'num_agent_steps_sampled': 44000, 'num_agent_steps_trained': 44000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 44000, 'num_agent_steps_trained': 44000, 'num_env_steps_sampled': 44000, 'num_env_steps_trained': 44000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 429.3278890232019, 'num_env_steps_trained_throughput_per_sec': 429.3278890232019, 'timesteps_total': 44000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 44000, 'timers': {'training_iteration_time_ms': 9255.606, 'sample_time_ms': 5370.759, 'load_time_ms': 0.493, 'load_throughput': 8112381.413, 'learn_time_ms': 3884.11, 'learn_throughput': 1029.837, 'synch_weights_time_ms': 0.002}, 'counters': {'num_env_steps_sampled': 44000, 'num_env_steps_trained': 44000, 'num_agent_steps_sampled': 44000, 'num_agent_steps_trained': 44000}, 'done': False, 'episodes_total': 0, 'training_iteration': 11, 'trial_id': 'default', 'date': '2024-09-23_12-21-07', 'timestamp': 1727094067, 'time_this_iter_s': 9.316947937011719, 'time_total_s': 103.92248773574829, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 103.92248773574829, 'iterations_since_restore': 11, 'perf': {'cpu_util_percent': 4.923076923076923, 'ram_util_percent': 16.730769230769226}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.006250000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937412367584885, 'policy_loss': -0.06264620069614661, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.00936962626223524, 'entropy': 0.9996994412073525, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 10695.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 48000, 'num_env_steps_trained': 48000, 'num_agent_steps_sampled': 48000, 'num_agent_steps_trained': 48000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 48000, 'num_agent_steps_trained': 48000, 'num_env_steps_sampled': 48000, 'num_env_steps_trained': 48000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 439.2917232870108, 'num_env_steps_trained_throughput_per_sec': 439.2917232870108, 'timesteps_total': 48000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 48000, 'timers': {'training_iteration_time_ms': 9218.412, 'sample_time_ms': 5350.587, 'load_time_ms': 0.488, 'load_throughput': 8195201.25, 'learn_time_ms': 3867.095, 'learn_throughput': 1034.368, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 48000, 'num_env_steps_trained': 48000, 'num_agent_steps_sampled': 48000, 'num_agent_steps_trained': 48000}, 'done': False, 'episodes_total': 0, 'training_iteration': 12, 'trial_id': 'default', 'date': '2024-09-23_12-21-17', 'timestamp': 1727094077, 'time_this_iter_s': 9.105628490447998, 'time_total_s': 113.02811622619629, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 113.02811622619629, 'iterations_since_restore': 12, 'perf': {'cpu_util_percent': 4.8, 'ram_util_percent': 16.73076923076923}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.006250000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937579785623859, 'policy_loss': -0.06248229938729476, 'vf_loss': 10.0, 'vf_explained_var': 0.7428363177084154, 'kl': 0.009934977418054595, 'entropy': 0.9657743133524412, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 11625.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 52000, 'num_env_steps_trained': 52000, 'num_agent_steps_sampled': 52000, 'num_agent_steps_trained': 52000}, 'sampler_results': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 52000, 'num_agent_steps_trained': 52000, 'num_env_steps_sampled': 52000, 'num_env_steps_trained': 52000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 434.45694047744644, 'num_env_steps_trained_throughput_per_sec': 434.45694047744644, 'timesteps_total': 52000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 52000, 'timers': {'training_iteration_time_ms': 9195.02, 'sample_time_ms': 5341.906, 'load_time_ms': 0.485, 'load_throughput': 8254066.713, 'learn_time_ms': 3852.388, 'learn_throughput': 1038.317, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 52000, 'num_env_steps_trained': 52000, 'num_agent_steps_sampled': 52000, 'num_agent_steps_trained': 52000}, 'done': False, 'episodes_total': 0, 'training_iteration': 13, 'trial_id': 'default', 'date': '2024-09-23_12-21-26', 'timestamp': 1727094086, 'time_this_iter_s': 9.20695424079895, 'time_total_s': 122.23507046699524, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 122.23507046699524, 'iterations_since_restore': 13, 'perf': {'cpu_util_percent': 4.938461538461538, 'ram_util_percent': 16.7076923076923}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.006250000000000001, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.947015988954934, 'policy_loss': -0.042906610827933074, 'vf_loss': 9.989899379976334, 'vf_explained_var': 0.517211147341677, 'kl': 0.003714645180662046, 'entropy': 0.9122502916602678, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 12555.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 56000, 'num_env_steps_trained': 56000, 'num_agent_steps_sampled': 56000, 'num_agent_steps_trained': 56000}, 'sampler_results': {'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episode_media': {}, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episodes_this_iter': 1, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 56000, 'num_agent_steps_trained': 56000, 'num_env_steps_sampled': 56000, 'num_env_steps_trained': 56000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 419.33899458265586, 'num_env_steps_trained_throughput_per_sec': 419.33899458265586, 'timesteps_total': 56000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 56000, 'timers': {'training_iteration_time_ms': 9229.245, 'sample_time_ms': 5372.811, 'load_time_ms': 0.484, 'load_throughput': 8256097.633, 'learn_time_ms': 3855.721, 'learn_throughput': 1037.419, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 56000, 'num_env_steps_trained': 56000, 'num_agent_steps_sampled': 56000, 'num_agent_steps_trained': 56000}, 'done': False, 'episodes_total': 1, 'training_iteration': 14, 'trial_id': 'default', 'date': '2024-09-23_12-21-35', 'timestamp': 1727094095, 'time_this_iter_s': 9.538930416107178, 'time_total_s': 131.77400088310242, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 131.77400088310242, 'iterations_since_restore': 14, 'perf': {'cpu_util_percent': 4.992857142857142, 'ram_util_percent': 16.72857142857143}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.0031250000000000006, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937673968653526, 'policy_loss': -0.062343372308438824, 'vf_loss': 10.0, 'vf_explained_var': 0.7434762712447874, 'kl': 0.005554944679256208, 'entropy': 0.8954381872248905, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 13485.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000}, 'sampler_results': {'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000, 'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 441.3637393089975, 'num_env_steps_trained_throughput_per_sec': 441.3637393089975, 'timesteps_total': 60000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 60000, 'timers': {'training_iteration_time_ms': 9236.244, 'sample_time_ms': 5376.847, 'load_time_ms': 0.486, 'load_throughput': 8225335.098, 'learn_time_ms': 3858.683, 'learn_throughput': 1036.623, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 60000, 'num_env_steps_trained': 60000, 'num_agent_steps_sampled': 60000, 'num_agent_steps_trained': 60000}, 'done': False, 'episodes_total': 1, 'training_iteration': 15, 'trial_id': 'default', 'date': '2024-09-23_12-21-44', 'timestamp': 1727094104, 'time_this_iter_s': 9.062922716140747, 'time_total_s': 140.83692359924316, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 140.83692359924316, 'iterations_since_restore': 15, 'perf': {'cpu_util_percent': 4.838461538461539, 'ram_util_percent': 16.738461538461536}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.0031250000000000006, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937468506187521, 'policy_loss': -0.06256337316446407, 'vf_loss': 10.0, 'vf_explained_var': 0.7434722992681688, 'kl': 0.010197478824455347, 'entropy': 0.8660992970389705, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 14415.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 64000, 'num_env_steps_trained': 64000, 'num_agent_steps_sampled': 64000, 'num_agent_steps_trained': 64000}, 'sampler_results': {'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 64000, 'num_agent_steps_trained': 64000, 'num_env_steps_sampled': 64000, 'num_env_steps_trained': 64000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 424.8192534712454, 'num_env_steps_trained_throughput_per_sec': 424.8192534712454, 'timesteps_total': 64000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 64000, 'timers': {'training_iteration_time_ms': 9283.402, 'sample_time_ms': 5406.82, 'load_time_ms': 0.491, 'load_throughput': 8145465.845, 'learn_time_ms': 3875.864, 'learn_throughput': 1032.028, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 64000, 'num_env_steps_trained': 64000, 'num_agent_steps_sampled': 64000, 'num_agent_steps_trained': 64000}, 'done': False, 'episodes_total': 1, 'training_iteration': 16, 'trial_id': 'default', 'date': '2024-09-23_12-21-54', 'timestamp': 1727094114, 'time_this_iter_s': 9.415871143341064, 'time_total_s': 150.25279474258423, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 150.25279474258423, 'iterations_since_restore': 16, 'perf': {'cpu_util_percent': 4.976923076923077, 'ram_util_percent': 16.715384615384615}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.0031250000000000006, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.93769015753141, 'policy_loss': -0.06233473247097385, 'vf_loss': 10.0, 'vf_explained_var': 0.7434722992681688, 'kl': 0.007962554945572598, 'entropy': 0.8644505611670914, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 15345.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 68000, 'num_env_steps_trained': 68000, 'num_agent_steps_sampled': 68000, 'num_agent_steps_trained': 68000}, 'sampler_results': {'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 68000, 'num_agent_steps_trained': 68000, 'num_env_steps_sampled': 68000, 'num_env_steps_trained': 68000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 429.190272637839, 'num_env_steps_trained_throughput_per_sec': 429.190272637839, 'timesteps_total': 68000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 68000, 'timers': {'training_iteration_time_ms': 9302.554, 'sample_time_ms': 5433.359, 'load_time_ms': 0.493, 'load_throughput': 8115913.313, 'learn_time_ms': 3868.478, 'learn_throughput': 1033.998, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 68000, 'num_env_steps_trained': 68000, 'num_agent_steps_sampled': 68000, 'num_agent_steps_trained': 68000}, 'done': False, 'episodes_total': 1, 'training_iteration': 17, 'trial_id': 'default', 'date': '2024-09-23_12-22-03', 'timestamp': 1727094123, 'time_this_iter_s': 9.319974422454834, 'time_total_s': 159.57276916503906, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 159.57276916503906, 'iterations_since_restore': 17, 'perf': {'cpu_util_percent': 4.976923076923076, 'ram_util_percent': 16.800000000000004}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.0031250000000000006, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.936841407898934, 'policy_loss': -0.06320056316432773, 'vf_loss': 10.0, 'vf_explained_var': 0.7434722992681688, 'kl': 0.01343832115582641, 'entropy': 0.8301385004674234, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 16275.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 72000, 'num_env_steps_trained': 72000, 'num_agent_steps_sampled': 72000, 'num_agent_steps_trained': 72000}, 'sampler_results': {'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 72000, 'num_agent_steps_trained': 72000, 'num_env_steps_sampled': 72000, 'num_env_steps_trained': 72000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 421.4857330285404, 'num_env_steps_trained_throughput_per_sec': 421.4857330285404, 'timesteps_total': 72000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 72000, 'timers': {'training_iteration_time_ms': 9317.727, 'sample_time_ms': 5442.854, 'load_time_ms': 0.49, 'load_throughput': 8160918.377, 'learn_time_ms': 3874.145, 'learn_throughput': 1032.486, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 72000, 'num_env_steps_trained': 72000, 'num_agent_steps_sampled': 72000, 'num_agent_steps_trained': 72000}, 'done': False, 'episodes_total': 1, 'training_iteration': 18, 'trial_id': 'default', 'date': '2024-09-23_12-22-13', 'timestamp': 1727094133, 'time_this_iter_s': 9.490351438522339, 'time_total_s': 169.0631206035614, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 169.0631206035614, 'iterations_since_restore': 18, 'perf': {'cpu_util_percent': 4.95, 'ram_util_percent': 16.800000000000004}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.0031250000000000006, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937109368847262, 'policy_loss': -0.06291637447091841, 'vf_loss': 10.0, 'vf_explained_var': 0.7434722992681688, 'kl': 0.008244597669240208, 'entropy': 0.743893979377644, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 17205.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 76000, 'num_env_steps_trained': 76000, 'num_agent_steps_sampled': 76000, 'num_agent_steps_trained': 76000}, 'sampler_results': {'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 76000, 'num_agent_steps_trained': 76000, 'num_env_steps_sampled': 76000, 'num_env_steps_trained': 76000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 426.03431531831774, 'num_env_steps_trained_throughput_per_sec': 426.03431531831774, 'timesteps_total': 76000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 76000, 'timers': {'training_iteration_time_ms': 9320.348, 'sample_time_ms': 5445.359, 'load_time_ms': 0.49, 'load_throughput': 8165287.39, 'learn_time_ms': 3874.262, 'learn_throughput': 1032.455, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 76000, 'num_env_steps_trained': 76000, 'num_agent_steps_sampled': 76000, 'num_agent_steps_trained': 76000}, 'done': False, 'episodes_total': 1, 'training_iteration': 19, 'trial_id': 'default', 'date': '2024-09-23_12-22-22', 'timestamp': 1727094142, 'time_this_iter_s': 9.389018774032593, 'time_total_s': 178.452139377594, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 178.452139377594, 'iterations_since_restore': 19, 'perf': {'cpu_util_percent': 4.938461538461539, 'ram_util_percent': 16.800000000000004}}\n",
      "{'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.0031250000000000006, 'cur_lr': 5.0000000000000016e-05, 'total_loss': 9.937954069978447, 'policy_loss': -0.06205327365026679, 'vf_loss': 10.0, 'vf_explained_var': 0.7434722992681688, 'kl': 0.002355103040369408, 'entropy': 0.7752049792838352, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 18135.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'sampler_results': {'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episode_media': {}, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}}, 'episode_reward_max': 52847.0, 'episode_reward_min': 52847.0, 'episode_reward_mean': 52847.0, 'episode_len_mean': 52848.0, 'episodes_this_iter': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.10531743736480978, 'mean_inference_ms': 0.9118227153023475, 'mean_action_processing_ms': 0.08085990674980777, 'mean_env_wait_ms': 0.27974154846075877, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 431.98733217384626, 'num_env_steps_trained_throughput_per_sec': 431.98733217384626, 'timesteps_total': 80000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 80000, 'timers': {'training_iteration_time_ms': 9310.523, 'sample_time_ms': 5439.43, 'load_time_ms': 0.49, 'load_throughput': 8162903.712, 'learn_time_ms': 3870.366, 'learn_throughput': 1033.494, 'synch_weights_time_ms': 0.001}, 'counters': {'num_env_steps_sampled': 80000, 'num_env_steps_trained': 80000, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 80000}, 'done': False, 'episodes_total': 1, 'training_iteration': 20, 'trial_id': 'default', 'date': '2024-09-23_12-22-31', 'timestamp': 1727094151, 'time_this_iter_s': 9.259632349014282, 'time_total_s': 187.71177172660828, 'pid': 1037017, 'hostname': 'hvaclab-srv.ad.hvaiclab.internal', 'node_ip': '192.168.200.249', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 1.0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'num_learner_workers': 0, 'num_gpus_per_learner_worker': 0, 'num_cpus_per_learner_worker': 1, 'local_gpu_idx': 0, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'env': <class 'controllables.core.tools.ray.env.ExternalEnv'>, 'env_config': {'action_space': Dict('thermostat': Box(15.0, 20.0, (), float32)), 'observation_space': Dict('temperature': Box(-inf, inf, (), float32)), 'system': <function <lambda> at 0x7f1e8bf42d40>, 'reward_function': <function <lambda> at 0x7f1e8bf4e840>, 'episode_events': {'step': 'begin_zone_timestep_after_init_heat_balance'}}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'auto_wrap_old_gym_envs': True, 'action_mask_key': 'action_mask', '_is_atari': None, 'env_runner_cls': None, 'num_envs_per_worker': 1, 'enable_connectors': False, '_env_to_module_connector': None, '_module_to_env_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'validate_workers_after_construction': True, 'compress_observations': False, 'sampler_perf_stats_ema_coef': None, 'sample_async': -1, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'gamma': 0.99, 'lr': 5e-05, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size': 4000, 'train_batch_size_per_learner': None, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1d52d6e7a0>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'custom_async_evaluation_function': None, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'max_num_worker_restarts': 1000, 'delay_between_worker_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'worker_health_probe_timeout_s': 60, 'worker_restore_timeout_s': 1800, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, '_enable_new_api_stack': False, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': True, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 0}, 'time_since_restore': 187.71177172660828, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': 4.971428571428571, 'ram_util_percent': 16.800000000000004}}\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "for _ in range(20):\n",
    "    print(algo.train())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'evaluation': {'sampler_results': {'episode_reward_max': 52847.0,\n",
       "   'episode_reward_min': 52847.0,\n",
       "   'episode_reward_mean': 52847.0,\n",
       "   'episode_len_mean': 52848.0,\n",
       "   'episode_media': {},\n",
       "   'episodes_this_iter': 1,\n",
       "   'policy_reward_min': {},\n",
       "   'policy_reward_max': {},\n",
       "   'policy_reward_mean': {},\n",
       "   'custom_metrics': {},\n",
       "   'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]},\n",
       "   'sampler_perf': {'mean_raw_obs_processing_ms': 0.10564736058028298,\n",
       "    'mean_inference_ms': 0.9130532167985475,\n",
       "    'mean_action_processing_ms': 0.08103630806459351,\n",
       "    'mean_env_wait_ms': 0.26409723736386065,\n",
       "    'mean_env_render_ms': 0.0},\n",
       "   'num_faulty_episodes': 0,\n",
       "   'connector_metrics': {}},\n",
       "  'episode_reward_max': 52847.0,\n",
       "  'episode_reward_min': 52847.0,\n",
       "  'episode_reward_mean': 52847.0,\n",
       "  'episode_len_mean': 52848.0,\n",
       "  'episode_media': {},\n",
       "  'episodes_this_iter': 1,\n",
       "  'policy_reward_min': {},\n",
       "  'policy_reward_max': {},\n",
       "  'policy_reward_mean': {},\n",
       "  'custom_metrics': {},\n",
       "  'hist_stats': {'episode_reward': [52847.0], 'episode_lengths': [52848]},\n",
       "  'sampler_perf': {'mean_raw_obs_processing_ms': 0.10564736058028298,\n",
       "   'mean_inference_ms': 0.9130532167985475,\n",
       "   'mean_action_processing_ms': 0.08103630806459351,\n",
       "   'mean_env_wait_ms': 0.26409723736386065,\n",
       "   'mean_env_render_ms': 0.0},\n",
       "  'num_faulty_episodes': 0,\n",
       "  'connector_metrics': {},\n",
       "  'num_agent_steps_sampled_this_iter': 40000,\n",
       "  'num_env_steps_sampled_this_iter': 40000,\n",
       "  'timesteps_this_iter': 40000}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the simulation environment when we are done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<controllables.energyplus.systems.System at 0x7f1ec7124710>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/energyplus/events.py\", line 136, in cb_\n",
      "    return cb(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/energyplus/events.py\", line 166, in _state\n",
      "    self._event.__call__(\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/energyplus/events.py\", line 105, in __call__\n",
      "    return super().__call__(context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/callbacks.py\", line 415, in __call__\n",
      "    return self._callables.__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/callables.py\", line 81, in __call__\n",
      "    res[f] = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/tools/ray/env.py\", line 310, in <lambda>\n",
      "    ('step', lambda *args, **kwargs: tracker.step()),\n",
      "                                     ^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/tools/ray/env.py\", line 248, in step\n",
      "    self._manager.action.value = self.get_action()\n",
      "                                 ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/tools/ray/env.py\", line 262, in get_action\n",
      "    return super().get_action(observation=observation)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/tools/ray/env.py\", line 136, in get_action\n",
      "    return self._manager.get_action(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/.venv/lib/python3.11/site-packages/ray/rllib/env/external_env.py\", line 139, in get_action\n",
      "    return episode.wait_for_action(observation)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/.venv/lib/python3.11/site-packages/ray/rllib/env/external_env.py\", line 297, in wait_for_action\n",
      "    return self.action_queue.get(True, timeout=300.0)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/queue.py\", line 179, in get\n",
      "    raise Empty\n",
      "_queue.Empty\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/energyplus/systems.py\", line 100, in run\n",
      "    status = self._core.run(args=self._cli_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/energyplus/_core/__init__.py\", line 91, in run\n",
      "    self.hooks.__call__('run:post')\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/callbacks.py\", line 458, in __call__\n",
      "    return self[ref].__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/callbacks.py\", line 415, in __call__\n",
      "    return self._callables.__call__(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/core/callables.py\", line 81, in __call__\n",
      "    res[f] = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/AD/user/lab/EnergyPlus-OOEP/packages/controllables/energyplus/events.py\", line 141, in _raise_exc\n",
      "    raise Exception from __exc__\n",
      "Exception\n"
     ]
    }
   ],
   "source": [
    "system.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
